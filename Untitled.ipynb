{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrapping Twitter Data(WFH Sentiment Analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tweepy in c:\\users\\sanjay\\new_anaconda\\lib\\site-packages (3.8.0)\n",
      "Requirement already satisfied: requests>=2.11.1 in c:\\users\\sanjay\\new_anaconda\\lib\\site-packages (from tweepy) (2.22.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\sanjay\\new_anaconda\\lib\\site-packages (from tweepy) (1.3.0)\n",
      "Requirement already satisfied: six>=1.10.0 in c:\\users\\sanjay\\new_anaconda\\lib\\site-packages (from tweepy) (1.14.0)\n",
      "Requirement already satisfied: PySocks>=1.5.7 in c:\\users\\sanjay\\new_anaconda\\lib\\site-packages (from tweepy) (1.7.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\sanjay\\new_anaconda\\lib\\site-packages (from requests>=2.11.1->tweepy) (1.25.8)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\sanjay\\new_anaconda\\lib\\site-packages (from requests>=2.11.1->tweepy) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\sanjay\\new_anaconda\\lib\\site-packages (from requests>=2.11.1->tweepy) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sanjay\\new_anaconda\\lib\\site-packages (from requests>=2.11.1->tweepy) (2019.11.28)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\sanjay\\new_anaconda\\lib\\site-packages (from requests-oauthlib>=0.7.0->tweepy) (3.1.0)\n",
      "Requirement already satisfied: textblob in c:\\users\\sanjay\\new_anaconda\\lib\\site-packages (0.15.3)\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\users\\sanjay\\new_anaconda\\lib\\site-packages (from textblob) (3.4.5)\n",
      "Requirement already satisfied: six in c:\\users\\sanjay\\new_anaconda\\lib\\site-packages (from nltk>=3.1->textblob) (1.14.0)\n",
      "Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package brown to\n",
      "[nltk_data]     C:\\Users\\Sanjay\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package brown is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Sanjay\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Sanjay\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Sanjay\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package conll2000 to\n",
      "[nltk_data]     C:\\Users\\Sanjay\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package conll2000 is already up-to-date!\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     C:\\Users\\Sanjay\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "!pip install tweepy\n",
    "\n",
    "# TextBlob: textblob is the python library for processing textual data.\n",
    "\n",
    "# Install it using following pip command:\n",
    "!pip install textblob\n",
    "\n",
    "\n",
    "#Also, we need to install some corpora using following command:\n",
    "!python -m textblob.download_corpora\n",
    "\n",
    "#(Corpora is nothing but a large and structured set of texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import tweepy \n",
    "from tweepy import OAuthHandler \n",
    "from textblob import TextBlob \n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "  \n",
    "class TwitterClient(object): \n",
    "    ''' \n",
    "    Generic Twitter Class for sentiment analysis. \n",
    "    We create a TwitterClient class. This class contains all the methods to interact with Twitter API and parsing tweets. \n",
    "    We use __init__ function to handle the authentication of API client.\n",
    "    \n",
    "    '''\n",
    "    def __init__(self): \n",
    "        \n",
    "        # __init__ is the constructor for a class. The self variable represents the instance of the object itself.\n",
    "        # When a class defines an __init__() method, class instantiation automatically invokes __init__() for the newly-created class instance. \n",
    "        \n",
    "        ''' \n",
    "        Class constructor or initialization method. \n",
    "        '''\n",
    "        # keys and tokens from the Twitter Dev Console \n",
    "        \n",
    "        consumer_key = 'FIhX4jpCLqZDGREwUa2GWA6Ah'\n",
    "        consumer_secret = 'Z4Edh8TlIA1dMJy1nPPkbzvR8pg6kYMicwkuOqGGKdQoQF1Hyo'\n",
    "        access_token = '2965508819-V2Gf45AAlAu4E85IgIHDa47p1UaGb6np63V3OdZ'\n",
    "        access_token_secret = '6c9lVepbxMLEoUXkO3GgpTih0IfoDpaSWfpmTvg1TwDU1'\n",
    "        \n",
    "        # attempt authentication \n",
    "        try: \n",
    "            # create OAuthHandler object \n",
    "            self.auth = OAuthHandler(consumer_key, consumer_secret) \n",
    "            # set access token and secret \n",
    "            self.auth.set_access_token(access_token, access_token_secret) \n",
    "            # create tweepy API object to fetch tweets \n",
    "            self.api = tweepy.API(self.auth) \n",
    "\n",
    "        except: \n",
    "            print(\"Error: Authentication Failed\") \n",
    "  \n",
    "    def clean_tweet(self, tweet): \n",
    "        ''' \n",
    "        Utility function to clean tweet text by removing links, special characters \n",
    "        using simple regex statements. \n",
    "        '''\n",
    "        return(' '.join(re.sub(\"([,\\.():;!$%^&*\\d])|([^0-9A-Za-z \\t])\", \" \", tweet).split())) \n",
    "  \n",
    "    def get_tweet_sentiment(self, tweet): \n",
    "        ''' \n",
    "        Utility function to classify sentiment of passed tweet \n",
    "        using textblob's sentiment method \n",
    "        '''\n",
    "        # create TextBlob object of passed tweet text \n",
    "        analysis = TextBlob(self.clean_tweet(tweet)) \n",
    "        # set sentiment \n",
    "        if analysis.sentiment.polarity > 0: \n",
    "            return('positive')\n",
    "        elif analysis.sentiment.polarity == 0: \n",
    "            return ('neutral')\n",
    "        else: \n",
    "            return ('negative')\n",
    "  \n",
    "    def get_tweets(self, query, count = 100): \n",
    "        ''' \n",
    "        Main function to fetch tweets and parse them.\n",
    "        '''\n",
    "        # empty list to store parsed tweets \n",
    "        tweets = [] \n",
    "        \n",
    "        try: \n",
    "            # call twitter api to fetch tweets \n",
    "            fetched_tweets = self.api.search(q = query, count = count) \n",
    "              \n",
    "            # parsing tweets one by one \n",
    "            for tweet in fetched_tweets: \n",
    "                # empty dictionary to store required params of a tweet \n",
    "                parsed_tweet = {} \n",
    "  \n",
    "                # saving text of tweet \n",
    "                parsed_tweet['text'] = tweet.text\n",
    "                parsed_tweet['date'] = tweet.created_at\n",
    "                \n",
    "                # saving sentiment of tweet \n",
    "                parsed_tweet['sentiment'] = self.get_tweet_sentiment(tweet.text) \n",
    "  \n",
    "                # appending parsed tweet to tweets list \n",
    "                if tweet.retweet_count > 0: \n",
    "                    # if tweet has retweets, ensure that it is appended only once \n",
    "                    if parsed_tweet not in tweets: \n",
    "                        tweets.append(parsed_tweet) \n",
    "                else: \n",
    "                    tweets.append(parsed_tweet) \n",
    "  \n",
    "            # return parsed tweets \n",
    "            return (tweets) \n",
    "  \n",
    "        except tweepy.TweepError as e: \n",
    "            # print error (if any) \n",
    "            print(\"Error : \" + str(e)) \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(): \n",
    "    \n",
    "    # creating object of TwitterClient Class \n",
    "    api = TwitterClient() \n",
    "    \n",
    "    # calling function to get tweets \n",
    "    tweets = api.get_tweets(query = 'Work from home during lockdown', count = 1500) \n",
    "    \n",
    " \n",
    "    # picking positive tweets from tweets \n",
    "    ptweets = [tweet for tweet in tweets if tweet['sentiment'] == 'positive'] \n",
    "    \n",
    "    # percentage of positive tweets \n",
    "    print(\"Positive tweets percentage: {} %\".format(100*len(ptweets)/len(tweets))) \n",
    "    \n",
    "    # picking negative tweets from tweets \n",
    "    ntweets = [tweet for tweet in tweets if tweet['sentiment'] == 'negative'] \n",
    "    \n",
    "    # percentage of negative tweets \n",
    "    print(\"Negative tweets percentage: {} %\".format(100*len(ntweets)/len(tweets))) \n",
    "    \n",
    "    # percentage of neutral tweets \n",
    "    print(\"Neutral tweets percentage: {} % \".format(100*(len(tweets) - (len(ntweets) + len(ptweets)))/len(tweets))) \n",
    "  \n",
    "    # printing first 10 positive tweets \n",
    "    print(\"\\n\\nPositive tweets:\") \n",
    "    for tweet in ptweets[:10]: \n",
    "        print(tweet['text'])\n",
    "        # print(tweet['date'])\n",
    "  \n",
    "    # printing first 10 negative tweets \n",
    "    print(\"\\n\\nNegative tweets:\") \n",
    "    for tweet in ntweets[:10]: \n",
    "        print(tweet['text'])\n",
    "        # print(tweet['date'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive tweets percentage: 28.72340425531915 %\n",
      "Negative tweets percentage: 46.808510638297875 %\n",
      "Neutral tweets percentage: 24.46808510638298 % \n",
      "\n",
      "\n",
      "Positive tweets:\n",
      "RT @powerofyogesh: The seed for the IT¬†revolution¬†was  planted during ¬†#RajivGandhi's tenure. And that's what led to India becoming a softw‚Ä¶\n",
      "RT @VaishaliMaisur2: @Helix_Watches During quarantine, myself involved in many activities like Work From Home, Exercise, cooking new dishes‚Ä¶\n",
      "What did you during the pandemic #lockdown?\n",
      "\n",
      "Me: I dunno. Wrote a couple proposals. Read a book (most of it, anyway‚Ä¶ https://t.co/2EetHSeqv5\n",
      "Work from home has become the new normal during the COVID19 lockdown. This has eliminated the line where ‚Äúwork‚Äù end‚Ä¶ https://t.co/PFe257Il7j\n",
      "Work from home has become the new normal during the COVID19 lockdown. This has eliminated the line where ‚Äúwork‚Äù end‚Ä¶ https://t.co/UuwOTLpaS4\n",
      "@nehajoychauhan during lockdown, many households are self reliant due to 'work from home' option, thank you is leas‚Ä¶ https://t.co/RXpW8WQkTz\n",
      "All educational institutions are closed in Haryana,but Government Polytechnics are opened from 4/05/2020 by the ord‚Ä¶ https://t.co/T9AMnQ5D05\n",
      "All educational institutions are closed in Haryana,but Government Polytechnics are opened from 4/05/2020 by the ord‚Ä¶ https://t.co/qgUfVK5EX6\n",
      "@GavinWilliamson #thankateacherday for buying own laptops, tablets, printers &amp; broadband to work from home at eveni‚Ä¶ https://t.co/80jxCTnzwk\n",
      "RT @powerofyogesh: The seed for the IT¬†revolution¬†was  planted during ¬†#RajivGandhi's tenure. And that's what led to India becoming a softw‚Ä¶\n",
      "\n",
      "\n",
      "Negative tweets:\n",
      "#TNEB @PThangamanioffl please restore power supply in mandaveli R k mutt road. Difficult to work from home during l‚Ä¶ https://t.co/fsvRqhfKG6\n",
      "RT @MABIN2_: Being anything but rich during lockdown is terrible. I should be walking down to my home gym as we speak &amp; lounging by a pool‚Ä¶\n",
      "RT @paulamusiitwa: We're supposed to work from home during lockdown, but land offices, civil courts and some other government entities are‚Ä¶\n",
      "RT @MABIN2_: Being anything but rich during lockdown is terrible. I should be walking down to my home gym as we speak &amp; lounging by a pool‚Ä¶\n",
      "RT @MABIN2_: Being anything but rich during lockdown is terrible. I should be walking down to my home gym as we speak &amp; lounging by a pool‚Ä¶\n",
      "RT @MABIN2_: Being anything but rich during lockdown is terrible. I should be walking down to my home gym as we speak &amp; lounging by a pool‚Ä¶\n",
      "RT @MABIN2_: Being anything but rich during lockdown is terrible. I should be walking down to my home gym as we speak &amp; lounging by a pool‚Ä¶\n",
      "RT @MABIN2_: Being anything but rich during lockdown is terrible. I should be walking down to my home gym as we speak &amp; lounging by a pool‚Ä¶\n",
      "RT @MABIN2_: Being anything but rich during lockdown is terrible. I should be walking down to my home gym as we speak &amp; lounging by a pool‚Ä¶\n",
      "RT @MABIN2_: Being anything but rich during lockdown is terrible. I should be walking down to my home gym as we speak &amp; lounging by a pool‚Ä¶\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\": \n",
    "    # calling main function \n",
    "    main() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(): \n",
    "    \n",
    "    # creating object of TwitterClient Class \n",
    "    api = TwitterClient() \n",
    "    \n",
    "    # calling function to get tweets \n",
    "    tweets = api.get_tweets(query = '#WFH', count = 1500) \n",
    "    \n",
    " \n",
    "    # picking positive tweets from tweets \n",
    "    ptweets = [tweet for tweet in tweets if tweet['sentiment'] == 'positive'] \n",
    "    \n",
    "    # percentage of positive tweets \n",
    "    print(\"Positive tweets percentage: {} %\".format(100*len(ptweets)/len(tweets))) \n",
    "    \n",
    "    # picking negative tweets from tweets \n",
    "    ntweets = [tweet for tweet in tweets if tweet['sentiment'] == 'negative'] \n",
    "    \n",
    "    # percentage of negative tweets \n",
    "    print(\"Negative tweets percentage: {} %\".format(100*len(ntweets)/len(tweets))) \n",
    "    \n",
    "    # percentage of neutral tweets \n",
    "    print(\"Neutral tweets percentage: {} % \".format(100*(len(tweets) - (len(ntweets) + len(ptweets)))/len(tweets))) \n",
    "  \n",
    "    # printing first 10 positive tweets \n",
    "    print(\"\\n\\nPositive tweets:\") \n",
    "    for tweet in ptweets[:10]: \n",
    "        print(tweet['text'])\n",
    "        # print(tweet['date'])\n",
    "  \n",
    "    # printing first 10 negative tweets \n",
    "    print(\"\\n\\nNegative tweets:\") \n",
    "    for tweet in ntweets[:10]: \n",
    "        print(tweet['text'])\n",
    "        # print(tweet['date'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive tweets percentage: 41.0 %\n",
      "Negative tweets percentage: 15.0 %\n",
      "Neutral tweets percentage: 44.0 % \n",
      "\n",
      "\n",
      "Positive tweets:\n",
      "Is it just me or do you guys start off your day by directly opening your laptop as well only to realize at 1PM that‚Ä¶ https://t.co/AuAiyNlAMu\n",
      "RT @Khatabook: The number of people working from home now is higher than it has ever been. Improving productivity while ensuring quality is‚Ä¶\n",
      "Our family (2 adults and 3 kids) don't own a car, but 2 cargo e-bikes. And we enjoyed #wfh (but 100% is a too much)‚Ä¶ https://t.co/MYsRYsLK3e\n",
      "Thanks Adrian for reminding me of this\n",
      "https://t.co/K9W6aFcq56\n",
      "\n",
      "#soundtrack #wfh #spotify https://t.co/gT4f6JnXDK\n",
      "RT @QUT: Are you spending more time sitting while working remotely? Try this quick and easy stretch to #stayactive during the work day. #WF‚Ä¶\n",
      "@MiaD @Eater This is why when I'm asked if it's not too hard to #WFH while supporting kid with #homeschooling and all.. I say NO, we're fine\n",
      "RT @frontierdev: As part of #MentalHealthAwarenessWeek we're sharing the new creative outlets we've picked up while #WFH. Programmer Philip‚Ä¶\n",
      "It's 3:30 AM and \"Parallel Universe\" is trending ofc it is. \n",
      "lol i feel like this was straight up from #HDIGH‚Ä¶ https://t.co/AIzvEBzEnX\n",
      "Unpopular opinion: calling someone cold during #WFH #lockdown is very impolite. \n",
      "You can mail and most things can b‚Ä¶ https://t.co/kG4DrG3Bmy\n",
      "Is #WFH  the future of work? No doubt advances in technology have made it possible for most employees to carry out‚Ä¶ https://t.co/b1vZcFtW4V\n",
      "\n",
      "\n",
      "Negative tweets:\n",
      "My 2 year old son asks me, ‚Äúwhat does adult mean?‚Äù I put my glass down, blow out the candles, turn off Enya, open a‚Ä¶ https://t.co/y3WWnVx2Ry\n",
      "Our everyday reality is constantly changing, especially when it comes to Intraday challenges. Our new white paper w‚Ä¶ https://t.co/arq2p4NVt8\n",
      "RT @NolanBusiness: Last chance to register for part 2 of our informative online event; Working Remotely with Dynamics GP. The event starts‚Ä¶\n",
      "ohh damn!! as usual I got up and started to work without realizing that today is a holiday..sometimes you lose trac‚Ä¶ https://t.co/OXIfBNAbY0\n",
      "RT @PavelkaWellness: How can you take care of your people as they work remotely?\n",
      "We've published a guide on‚Ä¶ https://t.co/1JclCSAUAQ\n",
      "Our everyday reality is constantly changing, especially when it comes to Intraday challenges. Our new white paper w‚Ä¶ https://t.co/3ZZs78s0VK\n",
      "Waited for 15 mins then realised my Zoom meeting is scheduled for tomorrow. Confused as always #zoom #WFH\n",
      "Fairly less number of votes to find comfort in. I feel #wfh is stressful but #remoteworking or #workfromanywhere wi‚Ä¶ https://t.co/NYIRtLy8tJ\n",
      "RT @JuttaEckstein: The 2020 budget got invalid due to Corona. Org structures don't work as intended bcs people are #WFH. Adhering to decisi‚Ä¶\n",
      "RT @fanifit16: Do nothing in #WFH ü§îüëà find a new job als not easy? Wanna try to build a serious #Tokenized but you are a Noob?\n",
      "\n",
      "Learn #DYCO‚Ä¶\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\": \n",
    "    # calling main function \n",
    "    main() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
